{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaFG29WskMZ4CtJyMvynNr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/Applied_Deep_Learning/blob/main/LeNet_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rMmLDAMLuwH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Directory to store CIFAR-10 data\n",
        "DATA_DIR = './data/cifar10'\n",
        "\n",
        "# Download CIFAR-10 using torchvision\n",
        "datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
        "datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
        "\n",
        "# File paths for extracted data\n",
        "train_dir = os.path.join(DATA_DIR, 'cifar-10-batches-py/train')\n",
        "test_dir = os.path.join(DATA_DIR, 'cifar-10-batches-py/test')\n",
        "\n",
        "# Define class names for CIFAR-10\n",
        "CLASSES = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "]\n",
        "\n",
        "# Custom Dataset class for CIFAR-10\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load dataset files\n",
        "        dataset = datasets.CIFAR10(root=DATA_DIR, train=train, download=True)\n",
        "        self.data = dataset.data\n",
        "        self.labels = dataset.targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read image and label\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Convert image to PIL format\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformation for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Create dataset instances for training and testing\n",
        "train_dataset = CIFAR10Dataset(root_dir=train_dir, train=True, transform=transform)\n",
        "test_dataset = CIFAR10Dataset(root_dir=test_dir, train=False, transform=transform)\n",
        "\n",
        "# Split training into train/validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define LeNet architecture for CIFAR-10 (input channels = 3)\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)  # 3 input channels for RGB images\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)            # Conv layer 2\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)                             # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(120, 84)                                      # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(84, 10)                                        # Fully connected layer 3 (10 classes)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)                   # Average pooling layer\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pool\n",
        "        x = self.pool(self.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool\n",
        "        x = x.view(-1, 16 * 5 * 5)               # Flatten tensor\n",
        "        x = self.relu(self.fc1(x))               # FC1 -> ReLU\n",
        "        x = self.relu(self.fc2(x))               # FC2 -> ReLU\n",
        "        x = self.fc3(x)                          # FC3\n",
        "        return x\n",
        "\n",
        "# Instantiate model and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Function to train one epoch\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "# Function to validate model\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(val_loader), accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_val_accuracy = 0.0\n",
        "best_model_path = './best_lenet_cifar10.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"Best model saved with accuracy: {best_val_accuracy:.2f}%\\n\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
        "print(f\"Best model loaded with accuracy: {best_val_accuracy:.2f}%\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = validate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKwJ2DXUNI1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}