{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/Applied_Deep_Learning/blob/main/LeNet_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label:  CIFAR10 [0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck] <br>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1010/1*r8S5tF_6naagKOnlIcGXoQ.png\" alt=\"alternatetext\">"
      ],
      "metadata": {
        "id": "uxn-x9qQQM0H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9rMmLDAMLuwH",
        "outputId": "11d7beb0-15ca-496c-b431-30a8350758d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/20]\n",
            "Train Loss: 1.9622, Train Accuracy: 27.38%\n",
            "Validation Loss: 1.6297, Validation Accuracy: 40.24%\n",
            "Best model saved with accuracy: 40.24%\n",
            "\n",
            "Epoch [2/20]\n",
            "Train Loss: 1.5252, Train Accuracy: 44.92%\n",
            "Validation Loss: 1.4155, Validation Accuracy: 48.98%\n",
            "Best model saved with accuracy: 48.98%\n",
            "\n",
            "Epoch [3/20]\n",
            "Train Loss: 1.3524, Train Accuracy: 51.48%\n",
            "Validation Loss: 1.3419, Validation Accuracy: 52.01%\n",
            "Best model saved with accuracy: 52.01%\n",
            "\n",
            "Epoch [4/20]\n",
            "Train Loss: 1.2484, Train Accuracy: 55.20%\n",
            "Validation Loss: 1.2422, Validation Accuracy: 55.71%\n",
            "Best model saved with accuracy: 55.71%\n",
            "\n",
            "Epoch [5/20]\n",
            "Train Loss: 1.1642, Train Accuracy: 58.49%\n",
            "Validation Loss: 1.2089, Validation Accuracy: 56.81%\n",
            "Best model saved with accuracy: 56.81%\n",
            "\n",
            "Epoch [6/20]\n",
            "Train Loss: 1.0810, Train Accuracy: 61.95%\n",
            "Validation Loss: 1.1662, Validation Accuracy: 58.44%\n",
            "Best model saved with accuracy: 58.44%\n",
            "\n",
            "Epoch [7/20]\n",
            "Train Loss: 1.0141, Train Accuracy: 64.07%\n",
            "Validation Loss: 1.1530, Validation Accuracy: 59.94%\n",
            "Best model saved with accuracy: 59.94%\n",
            "\n",
            "Epoch [8/20]\n",
            "Train Loss: 0.9566, Train Accuracy: 66.27%\n",
            "Validation Loss: 1.1331, Validation Accuracy: 61.12%\n",
            "Best model saved with accuracy: 61.12%\n",
            "\n",
            "Epoch [9/20]\n",
            "Train Loss: 0.9020, Train Accuracy: 68.10%\n",
            "Validation Loss: 1.0908, Validation Accuracy: 62.77%\n",
            "Best model saved with accuracy: 62.77%\n",
            "\n",
            "Epoch [10/20]\n",
            "Train Loss: 0.8475, Train Accuracy: 69.92%\n",
            "Validation Loss: 1.1227, Validation Accuracy: 61.56%\n",
            "Epoch [11/20]\n",
            "Train Loss: 0.8002, Train Accuracy: 71.63%\n",
            "Validation Loss: 1.1220, Validation Accuracy: 62.31%\n",
            "Epoch [12/20]\n",
            "Train Loss: 0.7506, Train Accuracy: 73.47%\n",
            "Validation Loss: 1.1161, Validation Accuracy: 63.05%\n",
            "Best model saved with accuracy: 63.05%\n",
            "\n",
            "Epoch [13/20]\n",
            "Train Loss: 0.7173, Train Accuracy: 74.58%\n",
            "Validation Loss: 1.1680, Validation Accuracy: 62.76%\n",
            "Epoch [14/20]\n",
            "Train Loss: 0.6688, Train Accuracy: 76.33%\n",
            "Validation Loss: 1.2270, Validation Accuracy: 61.31%\n",
            "Epoch [15/20]\n",
            "Train Loss: 0.6394, Train Accuracy: 76.99%\n",
            "Validation Loss: 1.1691, Validation Accuracy: 63.68%\n",
            "Best model saved with accuracy: 63.68%\n",
            "\n",
            "Epoch [16/20]\n",
            "Train Loss: 0.6047, Train Accuracy: 78.53%\n",
            "Validation Loss: 1.2698, Validation Accuracy: 62.60%\n",
            "Epoch [17/20]\n",
            "Train Loss: 0.5668, Train Accuracy: 79.85%\n",
            "Validation Loss: 1.3126, Validation Accuracy: 60.60%\n",
            "Epoch [18/20]\n",
            "Train Loss: 0.5475, Train Accuracy: 80.26%\n",
            "Validation Loss: 1.4350, Validation Accuracy: 60.09%\n",
            "Epoch [19/20]\n",
            "Train Loss: 0.5130, Train Accuracy: 81.51%\n",
            "Validation Loss: 1.3433, Validation Accuracy: 61.98%\n",
            "Epoch [20/20]\n",
            "Train Loss: 0.4789, Train Accuracy: 82.92%\n",
            "Validation Loss: 1.4177, Validation Accuracy: 61.86%\n",
            "Best model loaded with accuracy: 63.68%\n",
            "Test Loss: 1.1920, Test Accuracy: 62.66%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Directory to store CIFAR-10 data\n",
        "DATA_DIR = './data/cifar10'\n",
        "\n",
        "# Download CIFAR-10 using torchvision\n",
        "datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
        "datasets.CIFAR10(root=DATA_DIR, train=False, download=True)\n",
        "\n",
        "# File paths for extracted data\n",
        "train_dir = os.path.join(DATA_DIR, 'cifar-10-batches-py/train')\n",
        "test_dir = os.path.join(DATA_DIR, 'cifar-10-batches-py/test')\n",
        "\n",
        "# Define class names for CIFAR-10\n",
        "CLASSES = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "]\n",
        "\n",
        "# Custom Dataset class for CIFAR-10\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load dataset files\n",
        "        dataset = datasets.CIFAR10(root=DATA_DIR, train=train, download=True)\n",
        "        self.data = dataset.data\n",
        "        self.labels = dataset.targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Read image and label\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Convert image to PIL format\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformation for CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Create dataset instances for training and testing\n",
        "train_dataset = CIFAR10Dataset(root_dir=train_dir, train=True, transform=transform)\n",
        "test_dataset = CIFAR10Dataset(root_dir=test_dir, train=False, transform=transform)\n",
        "\n",
        "# Split training into train/validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define LeNet architecture for CIFAR-10 (input channels = 3)\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)  # 3 input channels for RGB images\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)            # Conv layer 2\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)                             # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(120, 84)                                      # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(84, 10)                                        # Fully connected layer 3 (10 classes)\n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)                   # Average pooling layer\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pool\n",
        "        x = self.pool(self.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool\n",
        "        x = x.view(-1, 16 * 6 * 6)               # Flatten tensor\n",
        "        x = self.relu(self.fc1(x))               # FC1 -> ReLU\n",
        "        x = self.relu(self.fc2(x))               # FC2 -> ReLU\n",
        "        x = self.fc3(x)                          # FC3\n",
        "        return x\n",
        "\n",
        "# Instantiate model and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Function to train one epoch\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "# Function to validate model\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return running_loss / len(val_loader), accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_val_accuracy = 0.0\n",
        "best_model_path = './best_lenet_cifar10.pth'\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"Best model saved with accuracy: {best_val_accuracy:.2f}%\\n\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
        "print(f\"Best model loaded with accuracy: {best_val_accuracy:.2f}%\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = validate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualise the Weights"
      ],
      "metadata": {
        "id": "yXb17A15QSLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gzip\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Function to plot all filters in two rows: before → top, after → bottom\n",
        "def plot_kernels_before_after(model_before, model_after, layer_name, title):\n",
        "    layer_before = dict(model_before.named_modules())[layer_name].weight.data.cpu().numpy()\n",
        "    layer_after = dict(model_after.named_modules())[layer_name].weight.data.cpu().numpy()\n",
        "    num_kernels = layer_before.shape[0]\n",
        "\n",
        "    fig, axs = plt.subplots(2, num_kernels, figsize=(num_kernels * 2, 4)) # 2 rows, num_kernels columns\n",
        "\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "\n",
        "    for i in range(num_kernels):\n",
        "        # Plot BEFORE training\n",
        "        axs[0, i].imshow(layer_before[i, 0], cmap='gray')\n",
        "        axs[0, i].axis('off')\n",
        "        if i == 0:\n",
        "            axs[0, i].set_ylabel(\"Before\", fontsize=12)\n",
        "\n",
        "        # Plot AFTER training\n",
        "        axs[1, i].imshow(layer_after[i, 0], cmap='gray')\n",
        "        axs[1, i].axis('off')\n",
        "        if i == 0:\n",
        "            axs[1, i].set_ylabel(\"After\", fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create two models:\n",
        "# 1. model_before - for showing initial random weights\n",
        "# 2. model_after - for showing learned weights after training\n",
        "model_before = LeNet().to(device)\n",
        "model_after = LeNet().to(device)\n",
        "\n",
        "# Load trained model weights into model_after\n",
        "best_model_path = './best_lenet_cifar10.pth'\n",
        "model_after.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
        "print(f\"Best model loaded with accuracy: {best_val_accuracy:.2f}%\")\n",
        "\n",
        "# Plot all filters in two rows (before and after training)\n",
        "plot_kernels_before_after(model_before, model_after, 'conv1', 'Conv1 Kernels: Before vs After Training')\n"
      ],
      "metadata": {
        "id": "nKwJ2DXUNI1k",
        "outputId": "63221873-0e7a-489f-8588-086ce75e709c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded with accuracy: 63.68%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0XC5W2DNuNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}